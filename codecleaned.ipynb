{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all the standard packages will be installed and we check which version of the CLMM code is currently installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicomasii/opt/anaconda3/lib/python3.8/site-packages/clmm-1.0.5-py3.8.egg/clmm/theory/__init__.py:38: UserWarning: CLMM Backend requested `ccl' is not available, trying others...\n",
      "/Users/nicomasii/opt/anaconda3/lib/python3.8/site-packages/clmm-1.0.5-py3.8.egg/clmm/theory/__init__.py:48: UserWarning: * NumCosmo BACKEND also not available\n",
      "/Users/nicomasii/opt/anaconda3/lib/python3.8/site-packages/clmm-1.0.5-py3.8.egg/clmm/theory/__init__.py:45: UserWarning: * USING cluster_toolkit+astropy BACKEND\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try: import clmm\n",
    "except:\n",
    "    import notebook_install\n",
    "    notebook_install.install_clmm_pipeline(upgrade=False)\n",
    "    import clmm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy\n",
    "from astropy import units\n",
    "import clmm.dataops as da\n",
    "import clmm.galaxycluster as gc\n",
    "import clmm.theory as theory\n",
    "from clmm import Cosmology\n",
    "from clmm import support\n",
    "from clmm.support import mock_data as mock\n",
    "from clmm.support import sampler\n",
    "from clmm.support.sampler import *\n",
    "from clmm.support.sampler import fitters\n",
    "import random\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "plt.rcParams['font.family']=['gothambook','gotham','gotham-book','serif']\n",
    "\n",
    "clmm.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are working with the random modul we use random seed in the next step for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mock data, we need to define a true cosmology, which is currently done with astropy's cosmology library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmo = Cosmology(H0 = 70.0, Omega_dm0 = 0.27 - 0.045, Omega_b0 = 0.045, Omega_k0 = 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now set some parameters for a mock galaxy cluster:\n",
    "    cluster_data[k][0] = cluster_m\n",
    "    cluster_data[k][1] = concentration\n",
    "    cluster_data[k][2] = cluster_ra\n",
    "    cluster_data[k][3] = cluster_dec\n",
    "    cluster_data[k][4] = cluster_z\n",
    "    cluster_data[k][5] = ngals\n",
    "    cluster_data[k][6] = logm\n",
    "    cluster_data[k][7] = number density \n",
    "and print the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.15288075e+13 1.33415588e+13 1.81341290e+13 ... 1.11044687e+13\n",
      " 1.51481143e+13 8.47965710e+13]\n"
     ]
    }
   ],
   "source": [
    "lower_limit =13\n",
    "upper_limit =15\n",
    "nbinhist=100\n",
    "norm = (upper_limit-lower_limit)/nbinhist\n",
    "\n",
    "M_star = 2.e14\n",
    "b=4*10**(-5)\n",
    "numsamp= 10**6\n",
    "numstep = 10**4\n",
    "\n",
    "#define x range 1e12-1e15 in num steps\n",
    "x = np.logspace(lower_limit,upper_limit,numstep)\n",
    "#define y values from the function \n",
    "y = (b*(1/(x/M_star))*np.exp(-(x)/M_star))\n",
    "\n",
    "#calculate cumulative sum of the y values (numpy)\n",
    "y_cm = np.cumsum(y)\n",
    "y_cm = y_cm-min(y_cm)\n",
    "y_cm = y_cm/np.max(y_cm)\n",
    "\n",
    "#invert x and y variables (flipping)and interpolate that function \n",
    "f = interp1d(y_cm,x , fill_value=(0,1))\n",
    "#Generate N random numbers uniformly between 0 & 1: u_i~U(0,1)\n",
    "ynew = np.random.random(numsamp)\n",
    "#Using the Inverse of the CDF and the values u_i, compute x_i = F^-1(u_i)\n",
    "x_samp = f(ynew) \n",
    "\n",
    "#plot it to see the result\n",
    "plt.hist(x_samp, bins=np.logspace(lower_limit,upper_limit,nbinhist),weights=np.repeat(numsamp/sum(y*x),numsamp)/norm,label='samples')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.plot(x, y, '.',label='massfunction')\n",
    "plt.xlabel('log(M)')\n",
    "plt.ylabel('N')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(x_samp)\n",
    "\n",
    "#use that interpolated function to predict num samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31528807471533.21\n",
      "13341558778797.023\n",
      "18134129014534.47\n",
      "43311571151855.305\n",
      "57494243472142.664\n",
      "25109615886994.3\n",
      "27569500450545.688\n",
      "19950218520070.234\n",
      "16568380902613.531\n",
      "10166883725293.494\n",
      "10166883725293.494\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)   \n",
    "num = 10\n",
    "cluster_data = np.zeros((num,7))\n",
    "#m_star=1.8.e14\n",
    "for k in range(num):\n",
    "   #cluster_data[k][7] = np.random.randint(1.e(-8),1.e(-2))    \n",
    "    cluster_data[k][0] = x_samp[k] #masse\n",
    "    cluster_data[k][6] = np.log(cluster_data[k][0])/np.log(10)\n",
    "    cluster_data[k][2] = 0\n",
    "    cluster_data[k][3] = 0\n",
    "    cluster_data[k][4] = np.random.uniform(0.1,0.6)\n",
    "    cluster_data[k][1] = 5.72/((1+cluster_data[k][4])**0.71)*(cluster_data[k][0]/10.e14)**(-0.081)\n",
    "    cluster_data[k][5] = np.random.randint(50,10000)\n",
    "    print(cluster_data[k][0])\n",
    "    \n",
    "     \n",
    "#print(cluster_data)\n",
    "print(cluster_data[k][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "def inverse_transform_sampling(data, n_bins=40, n_samples=1000):\n",
    "    hist, bin_edges = np.histogram(data, bins=n_bins, density=True)\n",
    "    cum_values = np.zeros(bin_edges.shape)\n",
    "    cum_values[1:] = np.cumsum(hist*np.diff(bin_edges))\n",
    "    inv_cdf = interpolate.interp1d(cum_values, bin_edges)\n",
    "    r = np.random.rand(n_samples)\n",
    "    return inv_cdf(r)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#input mass\n",
    "#print(cluster_data[:,0])\n",
    "plt.hist(cluster_data[:,0], 50, density=1, facecolor='g', alpha=0.75)\n",
    "#plt.plot(cluster_data[:,0] ,  , \"ob\")\n",
    "plt.xlabel('M_input')\n",
    "plt.ylabel('N')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ideal_data = []\n",
    "noisy_data = []\n",
    "\n",
    "for k in range(num):\n",
    "    buggy_data = mock.generate_galaxy_catalog(cluster_data[k][0], \n",
    "                                              cluster_data[k][4], \n",
    "                                              cluster_data[k][1], \n",
    "                                                           cosmo, \n",
    "                                                       'chang13', \n",
    "                             zsrc_min = cluster_data[k][4] + 0.1,\n",
    "                                                 shapenoise=0.05, \n",
    "                                      photoz_sigma_unscaled=0.05, \n",
    "                                    ngals=int(cluster_data[k][5])) \n",
    "    \n",
    "    #sortiert nachher die galaxien raus die den falschen redshift besitzen\n",
    "    mask = buggy_data['z'] < cluster_data[k][4] \n",
    "    #die galaxien sollten entfernt werden nicht maskiert...nur vorr√ºbergehend\n",
    "   \n",
    "    buggy_data['z'] = np.where(buggy_data['z'] < cluster_data[k][4], \n",
    "                               np.random.uniform(cluster_data[k][4],\n",
    "                                            cluster_data[k][4]+0.1), \n",
    "                                                    buggy_data['z'])\n",
    "    \n",
    "    mask = buggy_data['z'] < cluster_data[k][4]\n",
    "    realredshift = buggy_data['z']\n",
    "    #print(sum(buggy_data['z']<=cluster_data[k][4]))\n",
    "\n",
    "    ideal_data.append(mock.generate_galaxy_catalog(cluster_data[k][0],\n",
    "                                                   cluster_data[k][4], \n",
    "                                                   cluster_data[k][1],\n",
    "                                                                cosmo,\n",
    "                                                            'chang13',\n",
    "                                  zsrc_min = cluster_data[k][4] + 0.1, \n",
    "                                     ngals = int(cluster_data[k][5]))) \n",
    "    noisy_data.append(buggy_data)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the redshifts to see of we have any redshifts under the cluster redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for k in range(num):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.hist(ideal_data[k]['z'], density = True, alpha=0.5, bins = 50, label='ideal data')\n",
    "    plt.hist(noisy_data[k]['z'], alpha=0.5, density = True, bins = 50, label='noisy data')\n",
    "    plt.axvline(x = cluster_data[k][4], color='orange', label = 'cluster redshift')\n",
    "    plt.xlabel(r'$z_{src}$', fontsize = 20)\n",
    "    plt.ylabel(r'$N(z$)', fontsize = 20)\n",
    "    plt.legend()\n",
    "    plt.xlim(0,5)\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compete the radius which we will need later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = []\n",
    "for k in range(num):\n",
    "    variable = clmm.dataops._compute_lensing_angles_astropy(cluster_data[k][2], \n",
    "                                                            cluster_data[k][3], \n",
    "                                                            ideal_data[k]['ra'], \n",
    "                                                            ideal_data[k]['dec'])\n",
    "    radius.append(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The galaxy catalogs are converted to a clmm.GalaxyCluster object and may be saved for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_object =[]\n",
    "\n",
    "for k in range(num):\n",
    "\n",
    "    cluster_id = \"CL_ideal\"\n",
    "    gc_object.append( clmm.GalaxyCluster(cluster_id, \n",
    "                                 cluster_data[k][2],\n",
    "                                 cluster_data[k][3],\n",
    "                                 cluster_data[k][4], \n",
    "                                     ideal_data[k]))\n",
    "    gc_object[k].save('ideal_GC_'+str(k)+'.pkl')\n",
    "\n",
    "gc_object =[]\n",
    "\n",
    "for k in range(num):\n",
    "\n",
    "    cluster_id = \"CL_noisy\"\n",
    "    gc_object.append( clmm.GalaxyCluster(cluster_id,\n",
    "                                 cluster_data[k][2],\n",
    "                                 cluster_data[k][3],\n",
    "                                 cluster_data[k][4], \n",
    "                                     noisy_data[k]))\n",
    "    gc_object[k].save('noisy_GC_'+str(k)+'.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any saved clmm.GalaxyCluster object may be read in for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_ideal = []\n",
    "cl_noisy = []\n",
    "for k in range(num):\n",
    "    cl_ideal.append (clmm.GalaxyCluster.load('ideal_GC_'+str(k)+'.pkl'))\n",
    "    cl_noisy.append (clmm.GalaxyCluster.load('noisy_GC_'+str(k)+'.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redshift of galaxies generated by mock data are distributed following the Chang. (2013) redshift distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for k in range(num):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.hist(cl_ideal[k].galcat['z'], density = True, bins = 50)\n",
    "    plt.axvline(x = cluster_data[k][4], color='orange', label = 'cluster redshift')\n",
    "    plt.xlabel(r'$z_{src}$', fontsize = 20)\n",
    "    plt.ylabel(r'$N(z$)', fontsize = 20)\n",
    "    plt.legend()\n",
    "    plt.xlim(0,5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deriving observables\n",
    "\n",
    "Computing shear\n",
    "\n",
    "clmm.GalaxyCluster.compute_tangential_and_cross_components calculates the tangential and cross shears for each source galaxy in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(num):\n",
    "    cl_ideal[k].compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "    cl_noisy[k].compute_tangential_and_cross_components(geometry=\"flat\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radially binning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = da.make_bins(0.2, 4, 15, method='evenwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(num):\n",
    "\n",
    "    a = cl_ideal[k].make_radial_profile(\"Mpc\",\n",
    "                      include_empty_bins=True, \n",
    "                               bins=bin_edges, \n",
    "                                  cosmo=cosmo, \n",
    "                         gal_ids_in_bins=True,)#return_binnumber=True does not work\n",
    "    \n",
    "    b = cl_noisy[k].make_radial_profile(\"Mpc\",\n",
    "                      include_empty_bins=True, \n",
    "                               bins=bin_edges,\n",
    "                                  cosmo=cosmo, \n",
    "                         gal_ids_in_bins=True,)\n",
    "    #masking\n",
    "    maski = cl_ideal[k].profile['z'] > cluster_data[k][4]\n",
    "    maskn = cl_noisy[k].profile['z'] > cluster_data[k][4]\n",
    "    mask= maski*maskn\n",
    "    cl_ideal[k].profile =  cl_ideal[k].profile[mask]\n",
    "    cl_noisy[k].profile =  cl_noisy[k].profile[mask]\n",
    "\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl_ideal[k].profile['gt_err'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the object acquires the clmm.GalaxyCluster.profile attribute.\n",
    "\n",
    "#Create the reduced tangential shear models\n",
    "We consider two options:\n",
    "\n",
    "First, the naive and wrong approach: the reduced tangential shear in a given radial bin ùëó is given by ùëîùë°(ùúÉùëó,‚ü®ùëßùë†‚ü©), where ‚ü®ùëßùë†‚ü© is the average redshift in the bin. In that case, the corresponding model is simply given by the fucntion below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reduced_tangential_shear_zdistrib(radius, \n",
    "                                              logm,\n",
    "                                              data,\n",
    "                                           catalog,\n",
    "                                           profile, \n",
    "                                         cluster_z,\n",
    "                                    concentration): \n",
    "    m = 10**logm\n",
    "    gt_model = []\n",
    "    for i in range(len(radius)):\n",
    "        \n",
    "        r = profile['radius'][i]\n",
    "        galist = profile['gal_id'][i]\n",
    "        \n",
    "        z_list = catalog.galcat['z'][galist]\n",
    "        shear = clmm.compute_reduced_tangential_shear(r,\n",
    "                                                      m,\n",
    "                                          concentration,\n",
    "                                              cluster_z,\n",
    "                                                 z_list, \n",
    "                                                  cosmo, \n",
    "                                         delta_mdef=200, \n",
    "                               halo_profile_model='nfw')\n",
    "        if len(galist) == 0:\n",
    "            gt_model.append(1e-16)\n",
    "            print(\"this is bad\")\n",
    "        else:\n",
    "            gt_model.append(np.mean(shear))\n",
    "\n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_reduced_tangential_shear_singlez(r,\n",
    "                                        logm,\n",
    "                                       z_src,\n",
    "                                   cluster_z,\n",
    "                              concentration):\n",
    "    m = 10.**logm\n",
    "    gt_model = clmm.compute_reduced_tangential_shear(r,\n",
    "                                                     m,\n",
    "                                         concentration,\n",
    "                                             cluster_z,\n",
    "                                                 z_src,\n",
    "                                                 cosmo,\n",
    "                                        delta_mdef=200,\n",
    "                              halo_profile_model='nfw')    \n",
    "    return gt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before fitting, let's first vizualise these models using the known true mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_model_ideal_singlez = []\n",
    "gt_model_ideal_zdistrib = []\n",
    "gt_model_noisy_singlez = []\n",
    "gt_model_noisy_zdistrib = []\n",
    "r=[]\n",
    "for k in range(num):\n",
    "    r.append(cl_ideal[k].profile['radius'])\n",
    "\n",
    "    gt_model_ideal_singlez.append(model_reduced_tangential_shear_singlez(r[k], \n",
    "                                                           cluster_data[k][6],\n",
    "                                                     cl_ideal[k].profile['z'],\n",
    "                                                           cluster_data[k][4], \n",
    "                                                          cluster_data[k][1]))\n",
    "    \n",
    "    gt_model_ideal_zdistrib.append(model_reduced_tangential_shear_zdistrib(r[k],\n",
    "                                                             cluster_data[k][6],\n",
    "                                                                  ideal_data[k],\n",
    "                                                                    cl_ideal[k], \n",
    "                                                            cl_ideal[k].profile,\n",
    "                                                             cluster_data[k][4], \n",
    "                                                            cluster_data[k][1]))\n",
    "    \n",
    "    gt_model_noisy_singlez.append(model_reduced_tangential_shear_singlez(r[k],\n",
    "                                                           cluster_data[k][6],\n",
    "                                                     cl_noisy[k].profile['z'],\n",
    "                                                           cluster_data[k][4], \n",
    "                                                          cluster_data[k][1]))\n",
    "    \n",
    "    gt_model_noisy_zdistrib.append(model_reduced_tangential_shear_zdistrib(r[k],\n",
    "                                                             cluster_data[k][6],\n",
    "                                                                  noisy_data[k], \n",
    "                                                                    cl_noisy[k], \n",
    "                                                            cl_noisy[k].profile,\n",
    "                                                             cluster_data[k][4], \n",
    "                                                            cluster_data[k][1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range (num):\n",
    "    print(k)\n",
    "    plt.figure(figsize=(20,8))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "\n",
    "    plt.title('ideal data', fontsize=20)\n",
    "    plt.errorbar(r[k],\n",
    "                 cl_ideal[k].profile['gt'],\n",
    "                 cl_ideal[k].profile['gt_err'],\n",
    "                 c='k',linestyle='', \n",
    "                 marker='o',\n",
    "                 label=r'ideal data, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],gt_model_ideal_zdistrib[k],'b', \n",
    "               label=r'model w/ zdistrib, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],gt_model_ideal_singlez[k],'-y', \n",
    "               label=r'model w/o zdistrib, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.xlabel('r [Mpc]', fontsize = 20)\n",
    "    plt.ylabel(r'$g_t$', fontsize = 20)\n",
    "    plt.xlim(min(cl_ideal[k].profile['radius']), max(cl_ideal[k].profile['radius']))\n",
    "    plt.legend(fontsize = 15)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "\n",
    "    plt.title('noisy data', fontsize=20)\n",
    "    plt.errorbar(r[k],\n",
    "                 cl_noisy[k].profile['gt'],\n",
    "                 cl_noisy[k].profile['gt_err'],\n",
    "                 c='k',\n",
    "                 linestyle='', \n",
    "                 marker='o',\n",
    "                 label=r'noisy data, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],\n",
    "               gt_model_noisy_zdistrib[k],\n",
    "               '-b', \n",
    "               label=r'model w/ zdistrib, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],\n",
    "               gt_model_noisy_singlez[k],\n",
    "               '-y',\n",
    "               label=r'model w/o zdistrib, $M_{input}$ = %.2e Msun' % cluster_data[k][0])\n",
    "    plt.xlabel('r [Mpc]', fontsize = 20)\n",
    "    plt.ylabel(r'$g_t$', fontsize = 20)\n",
    "    plt.xlim(min(cl_noisy[k].profile['radius']), max(cl_noisy[k].profile['radius']))\n",
    "    plt.ylim(min(gt_model_ideal_zdistrib[k]),max(gt_model_ideal_zdistrib[k]))\n",
    "    plt.legend(fontsize = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive model that uses the average redshift in the bin clearly does not give the right description of the ideal data (left panel), and will yield biased mass results if used for fitting (see below). For ideal data, the model that accounts for the redshift distribution is, by construction, an excellent description of the data (solid blue line). The same is true for noisy data (right panel), although the noise make the naive model appear \"less biased\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mass fitting\n",
    "We estimate the best-fit mass using scipy.optimize.curve_fit. We compare estimated mass for noisy and ideal data, using both models described above (naive with average redshift or the model taking into account the redshift distribution). The choice of fitting log10ùëÄ instead of ùëÄ lowers the range of pre-defined fitting bounds from several order of magnitude for the mass to unity. From the associated error Œî(log10ùëÄ) we calculate the error to mass as ŒîùëÄ=ùëÄùëìùëñùë°log(10)Œî(log10ùëÄ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est_ideal_zdistrib = [None]*num\n",
    "m_est_err_ideal_zdistrib = [None]*num\n",
    "for k in range(num):\n",
    "\n",
    "    func = lambda r, x : model_reduced_tangential_shear_zdistrib(r,x, \n",
    "                                                       ideal_data[k],\n",
    "                                                         cl_ideal[k], \n",
    "                                                 cl_ideal[k].profile, \n",
    "                                                  cluster_data[k][4], \n",
    "                                                  cluster_data[k][1])\n",
    "    popt,pcov = fitters['curve_fit'](func, \n",
    "                        cl_ideal[k].profile['radius'], \n",
    "                        cl_ideal[k].profile['gt'], \n",
    "                        cl_ideal[k].profile['gt_err'], bounds=[10.,16.], p0=14.6)\n",
    "\n",
    "    m_est_ideal_zdistrib[k] = 10.**popt[0]\n",
    "    m_est_err_ideal_zdistrib[k] =  m_est_ideal_zdistrib[k] * np.sqrt(pcov[0][0]) * np.log(10) \n",
    "print(popt[0])\n",
    "print(pcov[0][0])\n",
    "print(np.sqrt(pcov[0][0]))\n",
    "print(np.log(10))\n",
    "print(m_est_err_ideal_zdistrib)\n",
    "print(m_est_ideal_zdistrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est_ideal_singlez = [None]*num\n",
    "m_est_err_ideal_singlez = [None]*num\n",
    "for k in range(num):\n",
    "\n",
    "    funct = lambda r, logm : model_reduced_tangential_shear_singlez(r,\n",
    "                                                                 logm, \n",
    "                                             cl_ideal[k].profile['z'], \n",
    "                                                   cluster_data[k][4], \n",
    "                                                   cluster_data[k][1])\n",
    "    popt,pcov = fitters['curve_fit'](funct, \n",
    "                        cl_ideal[k].profile['radius'], \n",
    "                        cl_ideal[k].profile['gt'], \n",
    "                        cl_ideal[k].profile['gt_err'], bounds=[10.,17.])\n",
    "\n",
    "    m_est_ideal_singlez[k] = 10.**popt[0]\n",
    "    m_est_err_ideal_singlez[k] = m_est_ideal_singlez[k] * np.sqrt(pcov[0][0]) * np.log(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est_noisy_zdistrib = [None]*num\n",
    "m_est_err_noisy_zdistrib = [None]*num\n",
    "for k in range(num):\n",
    "    cluster_z = cluster_data[k][4]\n",
    "    concentration = cluster_data[k][1]\n",
    "    #logm = cluster_data[k][6]\n",
    "    funct = lambda r, logm : model_reduced_tangential_shear_zdistrib(r, \n",
    "                                                                  logm, \n",
    "                                                         noisy_data[k],\n",
    "                                                           cl_noisy[k], \n",
    "                                                   cl_noisy[k].profile, \n",
    "                                                    cluster_data[k][4], \n",
    "                                                    cluster_data[k][1]) \n",
    "    popt,pcov = fitters['curve_fit'](funct, \n",
    "                        cl_noisy[k].profile['radius'], \n",
    "                        cl_noisy[k].profile['gt'], \n",
    "                        cl_noisy[k].profile['gt_err'], bounds=[10.,16.])\n",
    "\n",
    "    m_est_noisy_zdistrib[k] = 10.**popt[0]\n",
    "    m_est_err_noisy_zdistrib[k] =  m_est_noisy_zdistrib[k] * np.sqrt(pcov[0][0]) * np.log(10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_est_noisy_singlez = [None]*num\n",
    "m_est_err_noisy_singlez =[None]*num\n",
    "for k in range(num):\n",
    "\n",
    "    funct = lambda r, logm : model_reduced_tangential_shear_singlez(r, \n",
    "                                                                 logm, \n",
    "                                             cl_noisy[k].profile['z'],\n",
    "                                                   cluster_data[k][4], \n",
    "                                                   cluster_data[k][1])\n",
    "    popt,pcov = fitters['curve_fit'](funct, \n",
    "                        cl_noisy[k].profile['radius'], \n",
    "                        cl_noisy[k].profile['gt'], \n",
    "                        cl_noisy[k].profile['gt_err'],bounds=[10.,16.])\n",
    "\n",
    "    m_est_noisy_singlez[k] = 10.**popt[0]\n",
    "    m_est_err_noisy_singlez[k] =  m_est_noisy_singlez[k] * np.sqrt(pcov[0][0]) * np.log(10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(num):\n",
    "    print(k)\n",
    "    print(f'Cluster {k}')\n",
    "    \n",
    "    print(f'The input mass = {cluster_data[k][0]:.2e} Msun\\n')\n",
    "\n",
    "    print(\"Without accounting for the redshift distribution in the model\\n\")\n",
    "    print(f'Best fit mass for ideal data = {m_est_ideal_singlez[k]:.2e} +/- {m_est_err_ideal_singlez[k]:.2e} Msun')\n",
    "    print(f'Best fit mass for noisy data = {m_est_noisy_singlez[k]:.2e} +/- {m_est_err_noisy_singlez[k]:.2e} Msun\\n')\n",
    "\n",
    "    print(\"Accounting for the redshift distribution in the model\\n\")\n",
    "    print(f'Best fit mass for ideal data = {m_est_ideal_zdistrib[k]:.2e} +/- {m_est_err_ideal_zdistrib[k]:.2e} Msun')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the reconstructed mass is biased when the redshift distribution is not accounted for in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the results\n",
    "For visualization purpose, we calculate the reduced tangential shear predicted by the model with estimated masses for noisy and ideal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_est_ideal_zdistrib = []\n",
    "gt_est_noisy_zdistrib = []\n",
    "gt_est_ideal_singlez = []\n",
    "gt_est_noisy_singlez = []\n",
    "\n",
    "for k in range(num):\n",
    "\n",
    "    gt_est_ideal_zdistrib.append(model_reduced_tangential_shear_zdistrib\n",
    "                                                                     (r[k],\n",
    "                                np.log(m_est_ideal_zdistrib[k])/np.log(10), \n",
    "                                                             ideal_data[k], \n",
    "                                                               cl_ideal[k], \n",
    "                                                       cl_ideal[k].profile, \n",
    "                                                        cluster_data[k][4], \n",
    "                                                       cluster_data[k][1]))\n",
    "\n",
    "    gt_est_noisy_zdistrib.append(model_reduced_tangential_shear_zdistrib\n",
    "                                                                     (r[k], \n",
    "                                np.log(m_est_noisy_zdistrib[k])/np.log(10), \n",
    "                                                             noisy_data[k], \n",
    "                                                               cl_noisy[k], \n",
    "                                                       cl_noisy[k].profile,\n",
    "                                                        cluster_data[k][4], \n",
    "                                                       cluster_data[k][1]))\n",
    "\n",
    "    gt_est_ideal_singlez.append(model_reduced_tangential_shear_singlez\n",
    "                                                                    (r[k], \n",
    "                                np.log(m_est_ideal_singlez[k])/np.log(10),\n",
    "                                                 cl_ideal[k].profile['z'],\n",
    "                                                       cluster_data[k][4], \n",
    "                                                      cluster_data[k][1]))\n",
    "    \n",
    "    gt_est_noisy_singlez.append(model_reduced_tangential_shear_singlez\n",
    "                                                                    (r[k],\n",
    "                                np.log(m_est_noisy_singlez[k])/np.log(10),\n",
    "                                                 cl_noisy[k].profile['z'],\n",
    "                                                       cluster_data[k][4],\n",
    "                                                      cluster_data[k][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare to tangential shear obtained with theoretical mass. We plot the reduced tangential shear models first when redshift distribution is accounted for in the model then for the naive approach, with respective best-fit masses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k in range(num):\n",
    "\n",
    "    plt.figure(figsize=( 20 , 6 ))\n",
    "    plt.subplot( 1 , 2 , 1 )\n",
    "    plt.title(r'tangential shear $g_t$ (ideal data)', fontsize=20)\n",
    "    plt.errorbar(r[k],\n",
    "                 cl_ideal[k].profile['gt'],\n",
    "                 cl_ideal[k].profile['gt_err'],\n",
    "                 c='k',\n",
    "                 linestyle='', \n",
    "                 marker='o', \n",
    "                 label=r'ideal data, $M_{input}$ = %.1e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],gt_est_ideal_zdistrib[k],'-b', \n",
    "           label=fr'model w/ zdistrib, M_fit = {m_est_ideal_zdistrib[k]:.2e} $\\pm$ {m_est_err_ideal_zdistrib[k]:.2e} Msun')\n",
    "    plt.loglog(r[k],gt_est_ideal_singlez[k],'-y',\\\n",
    "           label=fr'model w/o zdistrib, M_fit = {m_est_ideal_singlez[k]:.2e} $\\pm$ {m_est_err_ideal_singlez[k]:.2e} Msun')\n",
    "\n",
    "    plt.xlabel('r [Mpc]', fontsize = 20)\n",
    "    plt.ylabel(r'$g_t$', fontsize = 20)\n",
    "    plt.xlim(min(cl_ideal[k].profile['radius']), max(cl_ideal[k].profile['radius']))\n",
    "    plt.legend(fontsize = 15)\n",
    "\n",
    "\n",
    "    plt.subplot( 1 , 2 , 2 )\n",
    "    plt.title(r'tangential shear $g_t$ (noisy data)', fontsize=20)\n",
    "    plt.errorbar(r[k],cl_noisy[k].profile['gt'],cl_noisy[k].profile['gt_err'],c='k',linestyle='', marker='o', label=r'noisy data, $M_{input}$ = %.1e Msun' % cluster_data[k][0])\n",
    "    #plt.loglog(r,gt_model_noisy,'-r',  label='model, $M_{input}$ = %.3e Msun' % cluster_data[k][0])\n",
    "    plt.loglog(r[k],gt_est_noisy_zdistrib[k],'-b', \n",
    "           label=fr'model w/ zdistrib, M_fit = {m_est_noisy_zdistrib[k]:.2e} $\\pm$ {m_est_err_noisy_zdistrib[k]:.2e} Msun')\n",
    "    plt.loglog(r[k],gt_est_noisy_singlez[k],'-y', \n",
    "           label=fr'model w/o zdistrib, M_fit = {m_est_noisy_singlez[k]:.2e} $\\pm$ {m_est_err_noisy_singlez[k]:.2e} Msun')\n",
    "\n",
    "    plt.xlabel('r [Mpc]', fontsize = 20)\n",
    "    plt.ylabel(r'$g_t$', fontsize = 20)\n",
    "    plt.xlim(min(cl_noisy[k].profile['radius']), max(cl_noisy[k].profile['radius']))\n",
    "    plt.legend(fontsize = 15)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the average of the input masses\n",
    "cluster_data_mass_avg = np.average(cluster_data[:,0])\n",
    "#calculate the avere of the estimated mass (ideal data) (bad method)\n",
    "m_est_ideal_singlez_avg = np.average(m_est_ideal_singlez)\n",
    "#calculate the standarddeviation of the estimated mass (ideal data) (bad method)\n",
    "m_est_ideal_singlez_avg_err = np.sum(m_est_err_ideal_singlez)/np.size(m_est_err_ideal_singlez)\n",
    "\n",
    "\n",
    "#calculate the avere of the estimated mass (noisy data) (bad method)\n",
    "m_est_noisy_singlez_avg = np.average(m_est_noisy_singlez)\n",
    "#calculate the standarddeviation of the estimated mass (noisy data) (bad method)\n",
    "m_est_noisy_singlez_avg_err = np.sum(m_est_err_noisy_singlez)/np.size(m_est_err_noisy_singlez)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#calculate the avere of the estimated mass (ideal data)(good method)\n",
    "m_est_ideal_zdistrib_avg = np.average(m_est_ideal_zdistrib)\n",
    "#calculate the standarddeviation of the estimated mass (ideal data)(good method)\n",
    "m_est_ideal_zdistrib_avg_err = np.sum(m_est_err_ideal_zdistrib)/np.size(m_est_err_ideal_zdistrib)\n",
    "\n",
    "\n",
    "#calculate the avere of the estimated mass (noisy data)(good method)\n",
    "m_est_noisy_zdistrib_avg = np.average(m_est_noisy_zdistrib)\n",
    "#calculate the standarddeviation of the estimated mass (noisy data)(good method)\n",
    "m_est_noisy_zdistrib_avg_err = np.sum(m_est_err_noisy_zdistrib)/np.size(m_est_err_noisy_zdistrib)\n",
    "\n",
    "#print the averages:\n",
    "print(cluster_data_mass_avg)\n",
    "print(m_est_ideal_singlez_avg)\n",
    "print(m_est_ideal_singlez_avg_err)\n",
    "print(m_est_noisy_singlez_avg)\n",
    "print(m_est_ideal_zdistrib_avg)\n",
    "print(m_est_noisy_zdistrib_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input estimated masszdistrib\n",
    "plt.hist(m_est_ideal_singlez, 50,  facecolor='y', alpha=0.5, label=\"estimated mass ideal\")\n",
    "plt.hist(m_est_noisy_singlez, 50,  facecolor='b', alpha=0.5, label=\"estimated mass noisy\")\n",
    "plt.axvline(cluster_data_mass_avg, color='k', linestyle='solid', linewidth=1 , label=\"input mass average\")\n",
    "plt.axvline(m_est_ideal_singlez_avg, color='c', linestyle='solid', linewidth=1, label=\"estimated mass avg noisy\")\n",
    "plt.axvline(m_est_ideal_singlez_avg-m_est_ideal_singlez_avg_err, color='c', linestyle='dashed', linewidth=1, label=\"estimated mass avg err noisy\")\n",
    "plt.axvline(m_est_ideal_singlez_avg+m_est_ideal_singlez_avg_err, color='c', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(m_est_noisy_singlez_avg, color='r', linestyle='solid', linewidth=1, label=\"estimated mass avg ideal\")\n",
    "plt.axvline(m_est_noisy_singlez_avg-m_est_noisy_singlez_avg_err, color='r', linestyle='dashed', linewidth=1, label=\"estimated mass avg err ideal\")\n",
    "plt.axvline(m_est_noisy_singlez_avg+m_est_noisy_singlez_avg_err, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.hist(cluster_data[:,0], 50, facecolor='g', alpha=0.5 , label=\"input\")\n",
    "#plt.errorbar(m_est_ideal_singlez_avg,0, xerr=m_est_ideal_singlez_avg_err, fmt=\"\", color=\"r\")\n",
    "plt.xlabel('Estimated mass vs input mass bad method')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input estimated masszdistrib\n",
    "plt.hist(m_est_ideal_zdistrib, 50,  facecolor='y', alpha=0.5, label=\"estimated mass ideal\")\n",
    "plt.hist(m_est_noisy_zdistrib, 50,  facecolor='b', alpha=0.5, label=\"estimated mass noisy\")\n",
    "plt.axvline(cluster_data_mass_avg, color='k', linestyle='solid', linewidth=1 , label=\"input mass average\")\n",
    "plt.axvline(m_est_ideal_zdistrib_avg, color='c',alpha=0.5, linestyle='solid', linewidth=1, label=\"estimated mass avg noisy\")\n",
    "plt.axvline(m_est_ideal_zdistrib_avg-m_est_ideal_zdistrib_avg_err, color='c', linestyle='dashed', linewidth=1, label=\"estimated mass avg err noisy\")\n",
    "plt.axvline(m_est_ideal_zdistrib_avg+m_est_ideal_zdistrib_avg_err, color='c', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(m_est_noisy_zdistrib_avg, color='r', linestyle='solid', linewidth=1, label=\"estimated mass avg ideal\")\n",
    "plt.axvline(m_est_noisy_zdistrib_avg-m_est_noisy_zdistrib_avg_err, color='r', linestyle='dashed', linewidth=1, label=\"estimated mass avg err ideal\")\n",
    "plt.axvline(m_est_noisy_zdistrib_avg+m_est_noisy_zdistrib_avg_err, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.hist(cluster_data[:,0], 50, facecolor='g', alpha=0.5 , label=\"input\")\n",
    "#plt.errorbar(m_est_ideal_singlez_avg,0, xerr=m_est_ideal_singlez_avg_err, fmt=\"\", color=\"r\")\n",
    "plt.xlabel('Estimated mass vs input mass good method')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.ylabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from math import log, exp\n",
    "mean = np.log(m_est_noisy_singlez)/np.log(10)\n",
    "\n",
    "\n",
    "std = m_est_err_noisy_singlez\n",
    "print(mean)\n",
    "print(std)\n",
    "x_min=-100\n",
    "x_max=100\n",
    "x = np.linspace(x_min, x_max, 1000)\n",
    "for k in range(num):\n",
    "\n",
    "\n",
    "    y = scipy.stats.norm.pdf(x,mean[k],std[k])\n",
    "\n",
    "#plt.plot(x,y, color='coral')\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    plt.plot(x,y, color='coral')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Normal Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
